# Projeto de An√°lise e Observabilidade de Produtos HP

Este reposit√≥rio cont√©m o projeto completo desenvolvido para o Challenge Sprint - HP, abrangendo desde a coleta de dados (web scraping) at√© a an√°lise explorat√≥ria, rotulagem heur√≠stica, uma plataforma de observabilidade e um pipeline completo de Machine Learning para classifica√ß√£o de autenticidade de produtos HP. O projeto est√° organizado em m√≥dulos, cada um com suas depend√™ncias e instru√ß√µes de execu√ß√£o.

## üìÅ Estrutura do Reposit√≥rio

O projeto est√° organizado na seguinte estrutura de pastas:

```
. (diret√≥rio raiz)
‚îú‚îÄ‚îÄ backend/             # C√≥digo do backend (Flask) da plataforma de observabilidade
‚îú‚îÄ‚îÄ data/                # Datasets CSV (limpos, enriquecidos, mockados)
‚îú‚îÄ‚îÄ logs/                # Arquivos de log das execu√ß√µes
‚îú‚îÄ‚îÄ misc/                # Arquivos diversos (READMEs espec√≠ficos, todo.md, etc.)
‚îú‚îÄ‚îÄ notebooks/           # Jupyter Notebooks (IPYNB e HTML) para EDA e ML Pipeline
‚îú‚îÄ‚îÄ presentations/       # Apresenta√ß√µes (HTML) geradas
‚îú‚îÄ‚îÄ reports/             # Relat√≥rios (Markdown e PDF)
‚îú‚îÄ‚îÄ scripts/             # Scripts Python (scrapers, limpeza, EDA, rotulagem, etc.)
‚îú‚îÄ‚îÄ src/                 # Pipeline de Machine Learning modular (Sprint 3)
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering/    # Engenharia de features
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/          # Pr√©-processamento de dados
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # Treinamento de modelos
‚îÇ   ‚îú‚îÄ‚îÄ hyperparameter_optimization/  # Otimiza√ß√£o de hiperpar√¢metros
‚îÇ   ‚îú‚îÄ‚îÄ validation/             # Valida√ß√£o e compara√ß√£o de modelos
‚îÇ   ‚îú‚îÄ‚îÄ interpretation/         # Interpretabilidade de modelos
‚îÇ   ‚îú‚îÄ‚îÄ persistence/            # Persist√™ncia e versionamento
‚îÇ   ‚îî‚îÄ‚îÄ reporting/              # Gera√ß√£o de relat√≥rios
‚îú‚îÄ‚îÄ visualizations/      # Visualiza√ß√µes (PNG) geradas pela EDA
‚îî‚îÄ‚îÄ zips/                # Arquivos ZIP de entregas anteriores
```

## üöÄ Configura√ß√£o Inicial do Ambiente

Para rodar qualquer parte deste projeto, voc√™ precisar√° ter o Python 3.x e o Node.js (com pnpm) instalados em seu sistema.

### 1. Python

Certifique-se de ter o Python 3.x instalado. √â recomendado usar um ambiente virtual para gerenciar as depend√™ncias.

```bash
python3 -m venv venv_global
source venv_global/bin/activate
pip install --upgrade pip
```

### 2. Node.js e pnpm

Para o frontend, voc√™ precisar√° do Node.js e do pnpm (gerenciador de pacotes).

```bash
sudo apt install nodejs npm
sudo npm install -g pnpm
```

## üì¶ M√≥dulos do Projeto e Como Rodar

O projeto est√° dividido em tr√™s sprints principais:

- **Sprint 1**: Coleta e Processamento de Dados
- **Sprint 2**: An√°lise Explorat√≥ria e Plataforma de Observabilidade  
- **Sprint 3**: Pipeline de Machine Learning para Classifica√ß√£o de Autenticidade

Cada m√≥dulo do projeto possui suas pr√≥prias depend√™ncias e instru√ß√µes de execu√ß√£o. Certifique-se de estar no diret√≥rio raiz do projeto antes de executar os comandos.




## üöÄ Sprint 1: Coleta e Processamento de Dados

### 1. Web Scraping (Scripts em `scripts/`)

**Descri√ß√£o:** Coleta de dados de produtos HP do Mercado Livre e Americanas.

**Depend√™ncias:**
- `selenium`
- `beautifulsoup4`
- `pandas`
- `lxml`
- `chromium-browser` (para Selenium)

**Instala√ß√£o:**

```bash
pip install selenium beautifulsoup4 pandas lxml
sudo apt-get update
sudo apt-get install -y chromium-browser
```

**Como Rodar:**

- **`scripts/hp_scraper.py` (Mercado Livre):**
  ```bash
  python3 scripts/hp_scraper.py
  ```
  *Nota: Este script pode precisar de ajustes nos seletores CSS devido a mudan√ßas frequentes na estrutura do site.* 

- **`scripts/americanas_scraper.py` (Americanas - **Dados Mockados**):
  ```bash
  python3 scripts/americanas_scraper.py
  ```
  *Nota: O scraper da Americanas foi configurado para usar dados mockados devido √† complexidade e instabilidade dos seletores. O script `scripts/generate_americanas_mock_data.py` pode ser usado para gerar novos dados mockados.* 

- **`scripts/generate_demo_data.py` (Gerador de Dados Demo):**
  ```bash
  python3 scripts/generate_demo_data.py
  ```

### 2. Processamento de Dados (Scripts em `scripts/`)

**Descri√ß√£o:** Limpeza, padroniza√ß√£o e enriquecimento dos dados coletados.

**Depend√™ncias:**
- `pandas`

**Instala√ß√£o:**

```bash
pip install pandas
```

**Como Rodar:**

- **`scripts/data_cleaning.py` (Limpeza e Padroniza√ß√£o):
  ```bash
  python3 scripts/data_cleaning.py
  ```

- **`scripts/data_enrichment.py` (Enriquecimento):
  ```bash
  python3 scripts/data_enrichment.py
  ```

- **`scripts/data_integration.py` (Integra√ß√£o de M√∫ltiplas Fontes):
  ```bash
  python3 scripts/data_integration.py
  ```

### 3. Rotulagem Heur√≠stica (Scripts em `scripts/`)

**Descri√ß√£o:** Aplica√ß√£o de crit√©rios heur√≠sticos para classificar produtos como 


"original" ou "suspeito/pirata".

**Depend√™ncias:**
- `pandas`

**Instala√ß√£o:**

```bash
pip install pandas
```

**Como Rodar:**

- **`scripts/heuristic_labeling.py` (Rotulagem Heur√≠stica):
  ```bash
  python3 scripts/heuristic_labeling.py
  ```

- **`scripts/dataset_generation.py` (Gera√ß√£o do Dataset Estruturado):
  ```bash
  python3 scripts/dataset_generation.py
  ```

## üìä Sprint 2: An√°lise Explorat√≥ria e Observabilidade

### 4. An√°lise Explorat√≥ria de Dados (EDA) (Notebooks em `notebooks/`)

**Descri√ß√£o:** An√°lise explorat√≥ria e descritiva dos dados coletados, incluindo visualiza√ß√µes e insights.

**Depend√™ncias:**
- `pandas`
- `numpy`
- `matplotlib`
- `seaborn`
- `nltk`
- `wordcloud`
- `jupyter` (para abrir e executar o notebook)

**Instala√ß√£o:**

```bash
pip install pandas numpy matplotlib seaborn nltk wordcloud jupyter
python3 -c "import nltk; nltk.download("punkt", quiet=True); nltk.download("stopwords", quiet=True); nltk.download("rslp", quiet=True)"
```

**Como Rodar:**

- **`notebooks/eda_notebook.ipynb`:**
  Para abrir e executar o notebook, navegue at√© a pasta `notebooks/` e inicie o Jupyter Notebook:
  ```bash
  cd notebooks/
  jupyter notebook
  ```
  Em seu navegador, abra o arquivo `eda_notebook.ipynb`.

- **`scripts/eda_script.py` (Script de EDA - usado para gerar as visualiza√ß√µes no notebook):
  ```bash
  python3 scripts/eda_script.py
  ```

### 5. Plataforma de Observabilidade (Backend em `backend/`, Frontend em `hp-observability-frontend/`)

**Descri√ß√£o:** Aplica√ß√£o web para visualiza√ß√£o e monitoramento dos dados de produtos HP.

**Depend√™ncias:**
- **Backend (Flask):** `Flask`, `flask-cors`, `pandas` (se usar dados reais, mas aqui est√° mockado)
- **Frontend (React):** `react`, `react-dom`, `vite`, `tailwindcss`, `recharts`, `@radix-ui/react-*`, `lucide-react`

**Instala√ß√£o do Backend:**

```bash
cd backend/hp_observability_backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

**Como Rodar o Backend:**

```bash
cd backend/hp_observability_backend
source venv/bin/activate
python src/main.py
```

**Instala√ß√£o do Frontend:**

```bash
cd hp-observability-frontend
pnpm install
```

**Como Rodar o Frontend:**

```bash
cd hp-observability-frontend
pnpm run dev
```

*Nota: Certifique-se de que o backend esteja rodando antes de iniciar o frontend, pois o frontend consome a API do backend.*

## ü§ñ Sprint 3: Pipeline de Machine Learning

**Descri√ß√£o:** Pipeline completo de Machine Learning para classifica√ß√£o autom√°tica de produtos HP como "original" ou "suspeito/pirata" usando t√©cnicas avan√ßadas de feature engineering, m√∫ltiplos algoritmos de ML, otimiza√ß√£o de hiperpar√¢metros e interpretabilidade de modelos.

### Arquitetura do Pipeline ML

O pipeline segue uma arquitetura modular com separa√ß√£o clara de responsabilidades:

```
Raw Data ‚Üí Feature Engineering ‚Üí Preprocessing ‚Üí Model Training ‚Üí Hyperparameter Optimization ‚Üí Validation ‚Üí Interpretation ‚Üí Persistence ‚Üí Reporting
```

### Depend√™ncias do Pipeline ML

**Principais bibliotecas:**
- `scikit-learn` - Algoritmos de ML e utilit√°rios
- `pandas`, `numpy` - Manipula√ß√£o de dados
- `matplotlib`, `seaborn` - Visualiza√ß√µes
- `joblib` - Serializa√ß√£o de modelos
- `imbalanced-learn` - T√©cnicas para dados desbalanceados
- `reportlab` - Gera√ß√£o de relat√≥rios PDF

**Instala√ß√£o:**

```bash
pip install scikit-learn pandas numpy matplotlib seaborn joblib imbalanced-learn reportlab
```

### Como Rodar o Pipeline ML

#### Op√ß√£o 1: Pipeline Completo (Recomendado)

```bash
# Navegue para o diret√≥rio notebooks
cd notebooks/

# Execute o pipeline modular completo
python ml_pipeline_modular.py
```

#### Op√ß√£o 2: M√≥dulos Individuais

```bash
# 1. Feature Engineering
from src.feature_engineering import FeatureEngineeringPipeline
pipeline = FeatureEngineeringPipeline()
X, y = pipeline.fit_transform(df)

# 2. Preprocessing
from src.preprocessing import create_complete_preprocessing_pipeline
results = create_complete_preprocessing_pipeline(X, y, imbalance_method='smote')

# 3. Model Training & Optimization
from src.hyperparameter_optimization import optimize_multiple_models
models = ['random_forest', 'svm', 'logistic_regression']
optimization_results = optimize_multiple_models(models, X_train, y_train)

# 4. Model Validation
from src.validation import create_model_comparison_table
comparison = create_model_comparison_table(models_results, cv_results)

# 5. Model Interpretation
from src.interpretation import InterpretationPipeline
interpreter = InterpretationPipeline(feature_names, class_names)
importance = interpreter.analyze_feature_importance(model, X_train, y_train)

# 6. Model Recommendation
from src.reporting import ModelRecommendationSystem
recommender = ModelRecommendationSystem()
recommendation = recommender.recommend_model(models_results, cv_results)
```

#### Op√ß√£o 3: Exemplos e Testes

```bash
# Execute exemplos espec√≠ficos
python notebooks/hyperparameter_pipeline_example.py
python notebooks/preprocessing_example.py

# Execute testes para validar funcionamento
python notebooks/test_preprocessing.py
python notebooks/test_hyperparameter_pipeline.py
python notebooks/test_validation.py
python notebooks/test_interpretation.py
python notebooks/test_model_recommendation.py
```

### Funcionalidades do Pipeline ML

#### üîß Feature Engineering
- **Features de Texto**: Vetoriza√ß√£o TF-IDF de t√≠tulos e descri√ß√µes
- **Features Num√©ricas**: Normaliza√ß√£o de pre√ßos, ratings, contagem de reviews
- **Features Categ√≥ricas**: One-hot encoding para plataformas, tipos de produto
- **Features Derivadas**: Ratios de pre√ßo, m√©tricas de texto, indicadores de palavras-chave
- **An√°lise de Correla√ß√£o**: Remo√ß√£o autom√°tica de features altamente correlacionadas

#### ü§ñ Treinamento de Modelos
- **M√∫ltiplos Algoritmos**: Random Forest, SVM, Logistic Regression, Gradient Boosting
- **Valida√ß√£o Cruzada**: 5-fold stratified cross-validation
- **Balanceamento de Classes**: SMOTE e class weighting
- **Interface Consistente**: API uniforme para todos os modelos

#### ‚ö° Otimiza√ß√£o de Hiperpar√¢metros
- **Sele√ß√£o Inteligente**: Escolha autom√°tica entre GridSearchCV e RandomizedSearchCV
- **Gest√£o de Or√ßamento**: Or√ßamentos configur√°veis e limites de tempo
- **Otimiza√ß√£o Multi-Modelo**: Otimiza√ß√£o paralela de m√∫ltiplos modelos
- **Tracking de Progresso**: Monitoramento em tempo real

#### üìä Valida√ß√£o e Compara√ß√£o
- **M√©tricas Abrangentes**: Precision, recall, F1-score, AUC-ROC, accuracy
- **Testes Estat√≠sticos**: Testes de signific√¢ncia entre performances
- **Visualiza√ß√µes**: Curvas ROC, matrizes de confus√£o, heatmaps
- **An√°lise de Overfitting**: Detec√ß√£o autom√°tica de overfitting

#### üîç Interpretabilidade
- **Feature Importance**: An√°lise baseada em √°rvores e permuta√ß√£o
- **Explica√ß√£o de Predi√ß√µes**: Explica√ß√µes individuais com features contribuintes
- **Visualiza√ß√µes Interativas**: Plots de import√¢ncia e explica√ß√µes
- **Insights Autom√°ticos**: Gera√ß√£o autom√°tica de insights de neg√≥cio

#### üíæ Persist√™ncia e Versionamento
- **Versionamento Autom√°tico**: Tracking de vers√µes com metadata
- **Serializa√ß√£o Completa**: Salvamento de pipelines completos
- **Valida√ß√£o de Compatibilidade**: Verifica√ß√£o de esquemas ao carregar
- **Metadata Rica**: M√©tricas de performance, par√¢metros, schemas

#### üìà Recomenda√ß√£o Autom√°tica de Modelos
- **Restri√ß√µes de Neg√≥cio**: Configura√ß√£o de requisitos de accuracy, interpretabilidade
- **Avalia√ß√£o de Deploy**: An√°lise multi-crit√©rio para produ√ß√£o
- **Scoring Inteligente**: Combina m√©tricas t√©cnicas com requisitos de neg√≥cio
- **Relat√≥rios Executivos**: Recomenda√ß√µes business-friendly

### Resultados Esperados

- **Accuracy**: >85% no conjunto de teste
- **F1-Score**: >0.85 para classifica√ß√£o balanceada
- **AUC-ROC**: >0.90 para forte discrimina√ß√£o
- **Interpretabilidade**: Explica√ß√µes claras para decis√µes de neg√≥cio

### Arquivos Principais do Pipeline ML

```
src/
‚îú‚îÄ‚îÄ feature_engineering/     # Extra√ß√£o e transforma√ß√£o de features
‚îú‚îÄ‚îÄ preprocessing/           # Pr√©-processamento e divis√£o de dados
‚îú‚îÄ‚îÄ models/                 # Implementa√ß√µes de treinamento
‚îú‚îÄ‚îÄ hyperparameter_optimization/  # Otimiza√ß√£o autom√°tica
‚îú‚îÄ‚îÄ validation/             # Avalia√ß√£o e compara√ß√£o
‚îú‚îÄ‚îÄ interpretation/         # Explicabilidade
‚îú‚îÄ‚îÄ persistence/           # Persist√™ncia com versionamento
‚îú‚îÄ‚îÄ reporting/             # Gera√ß√£o de relat√≥rios
‚îî‚îÄ‚îÄ config.py              # Configura√ß√µes do pipeline
```

*Nota: Para documenta√ß√£o detalhada do pipeline ML, consulte `src/README.md`.*

## üèÅ Como Rodar o Projeto Completo (Passo a Passo)

Para rodar o projeto completo do zero, siga os passos abaixo na ordem:

### Configura√ß√£o Inicial do Ambiente

1. **Configura√ß√£o Inicial do Ambiente:** Siga as instru√ß√µes na se√ß√£o "Configura√ß√£o Inicial do Ambiente" para instalar Python, Node.js e pnpm.

### Sprint 1: Coleta e Processamento de Dados

2. **Web Scraping (Opcional - Use dados mockados para agilizar):**
   - Execute `python3 scripts/generate_demo_data.py` para gerar dados mockados do Mercado Livre.
   - Execute `python3 scripts/generate_americanas_mock_data.py` para gerar dados mockados da Americanas.

3. **Processamento de Dados:**
   - Execute `python3 scripts/data_cleaning.py`.
   - Execute `python3 scripts/data_enrichment.py`.
   - Execute `python3 scripts/data_integration.py`.

4. **Rotulagem Heur√≠stica:**
   - Execute `python3 scripts/heuristic_labeling.py`.
   - Execute `python3 scripts/dataset_generation.py`.

### Sprint 2: An√°lise Explorat√≥ria e Observabilidade

5. **An√°lise Explorat√≥ria de Dados (EDA):**
   - Navegue at√© a pasta `notebooks/` e inicie o Jupyter Notebook (`jupyter notebook`).
   - Abra e execute o `eda_notebook.ipynb` c√©lula por c√©lula.

6. **Plataforma de Observabilidade:**
   - **Backend:** Siga as instru√ß√µes de instala√ß√£o e execu√ß√£o do backend (`backend/hp_observability_backend`).
   - **Frontend:** Siga as instru√ß√µes de instala√ß√£o e execu√ß√£o do frontend (`hp-observability-frontend`).

### Sprint 3: Pipeline de Machine Learning

7. **Pipeline de Machine Learning:**
   - **Instala√ß√£o das depend√™ncias ML:**
     ```bash
     pip install scikit-learn pandas numpy matplotlib seaborn joblib imbalanced-learn reportlab
     ```
   
   - **Execu√ß√£o do Pipeline Completo:**
     ```bash
     cd notebooks/
     python ml_pipeline_modular.py
     ```
   
   - **Ou execute m√≥dulos individuais conforme necess√°rio (ver se√ß√£o Sprint 3 acima)**

8. **Testes e Valida√ß√£o (Opcional mas Recomendado):**
   ```bash
   python notebooks/test_preprocessing.py
   python notebooks/test_hyperparameter_pipeline.py
   python notebooks/test_validation.py
   python notebooks/test_interpretation.py
   python notebooks/test_model_recommendation.py
   ```

### Resultado Final

Ao final, voc√™ ter√°:

- **Dados coletados e processados** (Sprint 1)
- **An√°lise explorat√≥ria completa** com insights e visualiza√ß√µes (Sprint 2)
- **Plataforma de observabilidade** rodando em `http://localhost:5173` (Sprint 2)
- **Pipeline de ML completo** com modelos treinados, otimizados e prontos para produ√ß√£o (Sprint 3)
- **Relat√≥rios t√©cnicos e executivos** com recomenda√ß√µes de modelos (Sprint 3)
- **Sistema de classifica√ß√£o autom√°tica** de produtos HP por autenticidade (Sprint 3)

## üéØ Objetivos Alcan√ßados

### Sprint 1 ‚úÖ
- Coleta automatizada de dados de m√∫ltiplas fontes
- Limpeza e padroniza√ß√£o de dados
- Rotulagem heur√≠stica para classifica√ß√£o inicial

### Sprint 2 ‚úÖ  
- An√°lise explorat√≥ria abrangente com insights de neg√≥cio
- Plataforma web para monitoramento e observabilidade
- Visualiza√ß√µes interativas e dashboards

### Sprint 3 ‚úÖ
- Pipeline de ML modular e escal√°vel
- Classifica√ß√£o autom√°tica com >85% de accuracy
- Sistema de recomenda√ß√£o inteligente de modelos
- Interpretabilidade e explicabilidade completas
- Relat√≥rios t√©cnicos e executivos automatizados

## üìä M√©tricas de Sucesso

- **Cobertura de Dados**: >1000 produtos coletados e analisados
- **Accuracy do Modelo**: >85% na classifica√ß√£o de autenticidade
- **Tempo de Processamento**: <5 minutos para pipeline completo
- **Interpretabilidade**: Explica√ß√µes claras para 100% das predi√ß√µes
- **Automa√ß√£o**: Pipeline totalmente automatizado do dado bruto ao modelo em produ√ß√£o



