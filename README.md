# Projeto de AnÃ¡lise e Observabilidade de Produtos HP

Este repositÃ³rio contÃ©m o projeto completo desenvolvido para o Challenge Sprint - HP, abrangendo desde a coleta de dados (web scraping) atÃ© a anÃ¡lise exploratÃ³ria, rotulagem heurÃ­stica, uma plataforma de observabilidade e um pipeline completo de Machine Learning para classificaÃ§Ã£o de autenticidade de produtos HP. O projeto estÃ¡ organizado em mÃ³dulos, cada um com suas dependÃªncias e instruÃ§Ãµes de execuÃ§Ã£o.

## ğŸ“ Estrutura do RepositÃ³rio

O projeto estÃ¡ organizado na seguinte estrutura de pastas:

```
. (diretÃ³rio raiz)
â”œâ”€â”€ backend/             # CÃ³digo do backend (Flask) da plataforma de observabilidade
â”œâ”€â”€ data/                # Datasets CSV (limpos, enriquecidos, mockados)
â”œâ”€â”€ logs/                # Arquivos de log das execuÃ§Ãµes
â”œâ”€â”€ misc/                # Arquivos diversos (READMEs especÃ­ficos, todo.md, etc.)
â”œâ”€â”€ notebooks/           # Jupyter Notebooks (IPYNB e HTML) para EDA e ML Pipeline
â”œâ”€â”€ presentations/       # ApresentaÃ§Ãµes (HTML) geradas
â”œâ”€â”€ production_api/      # API de ProduÃ§Ã£o completa (Sprint 3)
â”‚   â”œâ”€â”€ app/                    # AplicaÃ§Ã£o Flask principal
â”‚   â”‚   â”œâ”€â”€ api/               # Endpoints REST
â”‚   â”‚   â”œâ”€â”€ services/          # ServiÃ§os de negÃ³cio (ML, scraping, etc.)
â”‚   â”‚   â”œâ”€â”€ utils/             # UtilitÃ¡rios (database, logging)
â”‚   â”‚   â””â”€â”€ models.py          # Modelos de database
â”‚   â”œâ”€â”€ config/                # ConfiguraÃ§Ãµes por ambiente
â”‚   â”œâ”€â”€ tests/                 # Testes unitÃ¡rios e de integraÃ§Ã£o
â”‚   â”œâ”€â”€ run_api.py             # Servidor principal
â”‚   â”œâ”€â”€ init_db.py             # InicializaÃ§Ã£o do database
â”‚   â””â”€â”€ requirements.txt       # DependÃªncias da API
â”œâ”€â”€ reports/             # RelatÃ³rios (Markdown e PDF)
â”œâ”€â”€ scripts/             # Scripts Python (scrapers, limpeza, EDA, rotulagem, etc.)
â”œâ”€â”€ src/                 # Pipeline de Machine Learning modular (Sprint 3)
â”‚   â”œâ”€â”€ feature_engineering/    # Engenharia de features
â”‚   â”œâ”€â”€ preprocessing/          # PrÃ©-processamento de dados
â”‚   â”œâ”€â”€ models/                 # Treinamento de modelos
â”‚   â”œâ”€â”€ hyperparameter_optimization/  # OtimizaÃ§Ã£o de hiperparÃ¢metros
â”‚   â”œâ”€â”€ validation/             # ValidaÃ§Ã£o e comparaÃ§Ã£o de modelos
â”‚   â”œâ”€â”€ interpretation/         # Interpretabilidade de modelos
â”‚   â”œâ”€â”€ persistence/            # PersistÃªncia e versionamento
â”‚   â””â”€â”€ reporting/              # GeraÃ§Ã£o de relatÃ³rios
â”œâ”€â”€ visualizations/      # VisualizaÃ§Ãµes (PNG) geradas pela EDA
â””â”€â”€ zips/                # Arquivos ZIP de entregas anteriores
```

## ğŸš€ ConfiguraÃ§Ã£o Inicial do Ambiente

Para rodar qualquer parte deste projeto, vocÃª precisarÃ¡ ter o Python 3.x e o Node.js (com pnpm) instalados em seu sistema.

### 1. Python

Certifique-se de ter o Python 3.x instalado. Ã‰ recomendado usar um ambiente virtual para gerenciar as dependÃªncias.

```bash
python3 -m venv venv_global
source venv_global/bin/activate
pip install --upgrade pip
```

### 2. Node.js e pnpm

Para o frontend, vocÃª precisarÃ¡ do Node.js e do pnpm (gerenciador de pacotes).

```bash
sudo apt install nodejs npm
sudo npm install -g pnpm
```

## ğŸ“¦ MÃ³dulos do Projeto e Como Rodar

O projeto estÃ¡ dividido em trÃªs sprints principais:

- **Sprint 1**: Coleta e Processamento de Dados
- **Sprint 2**: AnÃ¡lise ExploratÃ³ria e Plataforma de Observabilidade  
- **Sprint 3**: Pipeline de Machine Learning para ClassificaÃ§Ã£o de Autenticidade

Cada mÃ³dulo do projeto possui suas prÃ³prias dependÃªncias e instruÃ§Ãµes de execuÃ§Ã£o. Certifique-se de estar no diretÃ³rio raiz do projeto antes de executar os comandos.




## ğŸš€ Sprint 1: Coleta e Processamento de Dados

### 1. Web Scraping (Scripts em `scripts/`)

**DescriÃ§Ã£o:** Coleta de dados de produtos HP do Mercado Livre e Americanas.

**DependÃªncias:**
- `selenium`
- `beautifulsoup4`
- `pandas`
- `lxml`
- `chromium-browser` (para Selenium)

**InstalaÃ§Ã£o:**

```bash
pip install selenium beautifulsoup4 pandas lxml
sudo apt-get update
sudo apt-get install -y chromium-browser
```

**Como Rodar:**

- **`scripts/hp_scraper.py` (Mercado Livre):**
  ```bash
  python3 scripts/hp_scraper.py
  ```
  *Nota: Este script pode precisar de ajustes nos seletores CSS devido a mudanÃ§as frequentes na estrutura do site.* 

- **`scripts/americanas_scraper.py` (Americanas - **Dados Mockados**):
  ```bash
  python3 scripts/americanas_scraper.py
  ```
  *Nota: O scraper da Americanas foi configurado para usar dados mockados devido Ã  complexidade e instabilidade dos seletores. O script `scripts/generate_americanas_mock_data.py` pode ser usado para gerar novos dados mockados.* 

- **`scripts/generate_demo_data.py` (Gerador de Dados Demo):**
  ```bash
  python3 scripts/generate_demo_data.py
  ```

### 2. Processamento de Dados (Scripts em `scripts/`)

**DescriÃ§Ã£o:** Limpeza, padronizaÃ§Ã£o e enriquecimento dos dados coletados.

**DependÃªncias:**
- `pandas`

**InstalaÃ§Ã£o:**

```bash
pip install pandas
```

**Como Rodar:**

- **`scripts/data_cleaning.py` (Limpeza e PadronizaÃ§Ã£o):
  ```bash
  python3 scripts/data_cleaning.py
  ```

- **`scripts/data_enrichment.py` (Enriquecimento):
  ```bash
  python3 scripts/data_enrichment.py
  ```

- **`scripts/data_integration.py` (IntegraÃ§Ã£o de MÃºltiplas Fontes):
  ```bash
  python3 scripts/data_integration.py
  ```

### 3. Rotulagem HeurÃ­stica (Scripts em `scripts/`)

**DescriÃ§Ã£o:** AplicaÃ§Ã£o de critÃ©rios heurÃ­sticos para classificar produtos como 


"original" ou "suspeito/pirata".

**DependÃªncias:**
- `pandas`

**InstalaÃ§Ã£o:**

```bash
pip install pandas
```

**Como Rodar:**

- **`scripts/heuristic_labeling.py` (Rotulagem HeurÃ­stica):
  ```bash
  python3 scripts/heuristic_labeling.py
  ```

- **`scripts/dataset_generation.py` (GeraÃ§Ã£o do Dataset Estruturado):
  ```bash
  python3 scripts/dataset_generation.py
  ```

## ğŸ“Š Sprint 2: AnÃ¡lise ExploratÃ³ria e Observabilidade

### 4. AnÃ¡lise ExploratÃ³ria de Dados (EDA) (Notebooks em `notebooks/`)

**DescriÃ§Ã£o:** AnÃ¡lise exploratÃ³ria e descritiva dos dados coletados, incluindo visualizaÃ§Ãµes e insights.

**DependÃªncias:**
- `pandas`
- `numpy`
- `matplotlib`
- `seaborn`
- `nltk`
- `wordcloud`
- `jupyter` (para abrir e executar o notebook)

**InstalaÃ§Ã£o:**

```bash
pip install pandas numpy matplotlib seaborn nltk wordcloud jupyter
python3 -c "import nltk; nltk.download("punkt", quiet=True); nltk.download("stopwords", quiet=True); nltk.download("rslp", quiet=True)"
```

**Como Rodar:**

- **`notebooks/eda_notebook.ipynb`:**
  Para abrir e executar o notebook, navegue atÃ© a pasta `notebooks/` e inicie o Jupyter Notebook:
  ```bash
  cd notebooks/
  jupyter notebook
  ```
  Em seu navegador, abra o arquivo `eda_notebook.ipynb`.

- **`scripts/eda_script.py` (Script de EDA - usado para gerar as visualizaÃ§Ãµes no notebook):
  ```bash
  python3 scripts/eda_script.py
  ```

### 5. Plataforma de Observabilidade (Backend em `backend/`, Frontend em `hp-observability-frontend/`)

**DescriÃ§Ã£o:** AplicaÃ§Ã£o web para visualizaÃ§Ã£o e monitoramento dos dados de produtos HP.

**DependÃªncias:**
- **Backend (Flask):** `Flask`, `flask-cors`, `pandas` (se usar dados reais, mas aqui estÃ¡ mockado)
- **Frontend (React):** `react`, `react-dom`, `vite`, `tailwindcss`, `recharts`, `@radix-ui/react-*`, `lucide-react`

**InstalaÃ§Ã£o do Backend:**

```bash
cd backend/hp_observability_backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

**Como Rodar o Backend:**

```bash
cd backend/hp_observability_backend
source venv/bin/activate
python src/main.py
```

**InstalaÃ§Ã£o do Frontend:**

```bash
cd hp-observability-frontend
pnpm install
```

**Como Rodar o Frontend:**

```bash
cd hp-observability-frontend
pnpm run dev
```

*Nota: Certifique-se de que o backend esteja rodando antes de iniciar o frontend, pois o frontend consome a API do backend.*

## ğŸ¤– Sprint 3: Pipeline de Machine Learning e API de ProduÃ§Ã£o

**DescriÃ§Ã£o:** Pipeline completo de Machine Learning para classificaÃ§Ã£o automÃ¡tica de produtos HP como "original" ou "suspeito/pirata" usando tÃ©cnicas avanÃ§adas de feature engineering, mÃºltiplos algoritmos de ML, otimizaÃ§Ã£o de hiperparÃ¢metros e interpretabilidade de modelos. Inclui tambÃ©m uma API de produÃ§Ã£o completa para deploy e uso em tempo real do sistema de classificaÃ§Ã£o.

### Arquitetura do Pipeline ML

O pipeline segue uma arquitetura modular com separaÃ§Ã£o clara de responsabilidades:

```
Raw Data â†’ Feature Engineering â†’ Preprocessing â†’ Model Training â†’ Hyperparameter Optimization â†’ Validation â†’ Interpretation â†’ Persistence â†’ Reporting
```

### DependÃªncias do Pipeline ML

**Principais bibliotecas:**
- `scikit-learn` - Algoritmos de ML e utilitÃ¡rios
- `pandas`, `numpy` - ManipulaÃ§Ã£o de dados
- `matplotlib`, `seaborn` - VisualizaÃ§Ãµes
- `joblib` - SerializaÃ§Ã£o de modelos
- `imbalanced-learn` - TÃ©cnicas para dados desbalanceados
- `reportlab` - GeraÃ§Ã£o de relatÃ³rios PDF

**InstalaÃ§Ã£o:**

```bash
pip install scikit-learn pandas numpy matplotlib seaborn joblib imbalanced-learn reportlab
```

### Como Rodar o Pipeline ML

#### OpÃ§Ã£o 1: Pipeline Completo (Recomendado)

```bash
# Navegue para o diretÃ³rio notebooks
cd notebooks/

# Execute o pipeline modular completo
python ml_pipeline_modular.py
```

#### OpÃ§Ã£o 2: MÃ³dulos Individuais

```bash
# 1. Feature Engineering
from src.feature_engineering import FeatureEngineeringPipeline
pipeline = FeatureEngineeringPipeline()
X, y = pipeline.fit_transform(df)

# 2. Preprocessing
from src.preprocessing import create_complete_preprocessing_pipeline
results = create_complete_preprocessing_pipeline(X, y, imbalance_method='smote')

# 3. Model Training & Optimization
from src.hyperparameter_optimization import optimize_multiple_models
models = ['random_forest', 'svm', 'logistic_regression']
optimization_results = optimize_multiple_models(models, X_train, y_train)

# 4. Model Validation
from src.validation import create_model_comparison_table
comparison = create_model_comparison_table(models_results, cv_results)

# 5. Model Interpretation
from src.interpretation import InterpretationPipeline
interpreter = InterpretationPipeline(feature_names, class_names)
importance = interpreter.analyze_feature_importance(model, X_train, y_train)

# 6. Model Recommendation
from src.reporting import ModelRecommendationSystem
recommender = ModelRecommendationSystem()
recommendation = recommender.recommend_model(models_results, cv_results)
```

#### OpÃ§Ã£o 3: Exemplos e Testes

```bash
# Execute exemplos especÃ­ficos
python notebooks/hyperparameter_pipeline_example.py
python notebooks/preprocessing_example.py

# Execute testes para validar funcionamento
python notebooks/test_preprocessing.py
python notebooks/test_hyperparameter_pipeline.py
python notebooks/test_validation.py
python notebooks/test_interpretation.py
python notebooks/test_model_recommendation.py
```

### Funcionalidades do Pipeline ML

#### ğŸ”§ Feature Engineering
- **Features de Texto**: VetorizaÃ§Ã£o TF-IDF de tÃ­tulos e descriÃ§Ãµes
- **Features NumÃ©ricas**: NormalizaÃ§Ã£o de preÃ§os, ratings, contagem de reviews
- **Features CategÃ³ricas**: One-hot encoding para plataformas, tipos de produto
- **Features Derivadas**: Ratios de preÃ§o, mÃ©tricas de texto, indicadores de palavras-chave
- **AnÃ¡lise de CorrelaÃ§Ã£o**: RemoÃ§Ã£o automÃ¡tica de features altamente correlacionadas

#### ğŸ¤– Treinamento de Modelos
- **MÃºltiplos Algoritmos**: Random Forest, SVM, Logistic Regression, Gradient Boosting
- **ValidaÃ§Ã£o Cruzada**: 5-fold stratified cross-validation
- **Balanceamento de Classes**: SMOTE e class weighting
- **Interface Consistente**: API uniforme para todos os modelos

#### âš¡ OtimizaÃ§Ã£o de HiperparÃ¢metros
- **SeleÃ§Ã£o Inteligente**: Escolha automÃ¡tica entre GridSearchCV e RandomizedSearchCV
- **GestÃ£o de OrÃ§amento**: OrÃ§amentos configurÃ¡veis e limites de tempo
- **OtimizaÃ§Ã£o Multi-Modelo**: OtimizaÃ§Ã£o paralela de mÃºltiplos modelos
- **Tracking de Progresso**: Monitoramento em tempo real

#### ğŸ“Š ValidaÃ§Ã£o e ComparaÃ§Ã£o
- **MÃ©tricas Abrangentes**: Precision, recall, F1-score, AUC-ROC, accuracy
- **Testes EstatÃ­sticos**: Testes de significÃ¢ncia entre performances
- **VisualizaÃ§Ãµes**: Curvas ROC, matrizes de confusÃ£o, heatmaps
- **AnÃ¡lise de Overfitting**: DetecÃ§Ã£o automÃ¡tica de overfitting

#### ğŸ” Interpretabilidade
- **Feature Importance**: AnÃ¡lise baseada em Ã¡rvores e permutaÃ§Ã£o
- **ExplicaÃ§Ã£o de PrediÃ§Ãµes**: ExplicaÃ§Ãµes individuais com features contribuintes
- **VisualizaÃ§Ãµes Interativas**: Plots de importÃ¢ncia e explicaÃ§Ãµes
- **Insights AutomÃ¡ticos**: GeraÃ§Ã£o automÃ¡tica de insights de negÃ³cio

#### ğŸ’¾ PersistÃªncia e Versionamento
- **Versionamento AutomÃ¡tico**: Tracking de versÃµes com metadata
- **SerializaÃ§Ã£o Completa**: Salvamento de pipelines completos
- **ValidaÃ§Ã£o de Compatibilidade**: VerificaÃ§Ã£o de esquemas ao carregar
- **Metadata Rica**: MÃ©tricas de performance, parÃ¢metros, schemas

#### ğŸ“ˆ RecomendaÃ§Ã£o AutomÃ¡tica de Modelos
- **RestriÃ§Ãµes de NegÃ³cio**: ConfiguraÃ§Ã£o de requisitos de accuracy, interpretabilidade
- **AvaliaÃ§Ã£o de Deploy**: AnÃ¡lise multi-critÃ©rio para produÃ§Ã£o
- **Scoring Inteligente**: Combina mÃ©tricas tÃ©cnicas com requisitos de negÃ³cio
- **RelatÃ³rios Executivos**: RecomendaÃ§Ãµes business-friendly

### Resultados Esperados

- **Accuracy**: >85% no conjunto de teste
- **F1-Score**: >0.85 para classificaÃ§Ã£o balanceada
- **AUC-ROC**: >0.90 para forte discriminaÃ§Ã£o
- **Interpretabilidade**: ExplicaÃ§Ãµes claras para decisÃµes de negÃ³cio

### Arquivos Principais do Pipeline ML

```
src/
â”œâ”€â”€ feature_engineering/     # ExtraÃ§Ã£o e transformaÃ§Ã£o de features
â”œâ”€â”€ preprocessing/           # PrÃ©-processamento e divisÃ£o de dados
â”œâ”€â”€ models/                 # ImplementaÃ§Ãµes de treinamento
â”œâ”€â”€ hyperparameter_optimization/  # OtimizaÃ§Ã£o automÃ¡tica
â”œâ”€â”€ validation/             # AvaliaÃ§Ã£o e comparaÃ§Ã£o
â”œâ”€â”€ interpretation/         # Explicabilidade
â”œâ”€â”€ persistence/           # PersistÃªncia com versionamento
â”œâ”€â”€ reporting/             # GeraÃ§Ã£o de relatÃ³rios
â””â”€â”€ config.py              # ConfiguraÃ§Ãµes do pipeline
```

*Nota: Para documentaÃ§Ã£o detalhada do pipeline ML, consulte `src/README.md`.*

## ğŸš€ API de ProduÃ§Ã£o para ClassificaÃ§Ã£o HP

**DescriÃ§Ã£o:** Sistema completo de produÃ§Ã£o que integra o pipeline de ML em uma API REST robusta, com scraping automatizado, classificaÃ§Ã£o em tempo real, monitoramento de sistema e interface web para gestÃ£o e visualizaÃ§Ã£o.

### Arquitetura da API de ProduÃ§Ã£o

```
Web Scraping â†’ Database Storage â†’ ML Classification â†’ REST API â†’ Web Interface
     â†“              â†“                    â†“              â†“           â†“
Cron Jobs â†’ Product Storage â†’ Batch Processing â†’ API Endpoints â†’ Dashboard
```

### Componentes Principais

#### ğŸ”§ Core Services (`production_api/app/services/`)
- **ML Service**: Carregamento e gestÃ£o de modelos treinados
- **Classification Service**: ClassificaÃ§Ã£o de produtos com explicaÃ§Ãµes
- **Scraper Service**: Coleta automatizada de dados do Mercado Livre
- **Batch Processor**: Processamento em lote de produtos
- **Feature Service**: Engenharia de features em tempo real
- **Health Service**: Monitoramento de saÃºde do sistema
- **Performance Service**: MÃ©tricas e analytics de performance

#### ğŸ—„ï¸ Database Models (`production_api/app/models.py`)
- **Product**: Armazenamento de dados de produtos
- **Classification**: Resultados de classificaÃ§Ã£o com confianÃ§a
- **ScrapingJob**: HistÃ³rico e status de jobs de scraping
- **SystemHealth**: MÃ©tricas de saÃºde e performance do sistema

#### ğŸŒ REST API Endpoints (`production_api/app/api/routes.py`)
- `POST /api/classify` - ClassificaÃ§Ã£o de produto individual
- `GET /api/products` - Listagem de produtos com filtros
- `GET /api/products/{id}` - Detalhes de produto especÃ­fico
- `GET /api/health` - Status de saÃºde do sistema
- `GET /api/metrics` - MÃ©tricas de performance

#### âš™ï¸ Configuration & Deployment
- **Environment Management**: ConfiguraÃ§Ãµes por ambiente (dev/prod)
- **Database Migration**: Scripts de migraÃ§Ã£o e inicializaÃ§Ã£o
- **Cron Jobs**: Agendamento automÃ¡tico de scraping
- **Docker Support**: ContainerizaÃ§Ã£o para deploy

### DependÃªncias da API de ProduÃ§Ã£o

**Principais bibliotecas:**
- `Flask` - Framework web
- `SQLAlchemy` - ORM para database
- `Flask-CORS` - Suporte a CORS
- `APScheduler` - Agendamento de tarefas
- `psycopg2` - Driver PostgreSQL
- `selenium` - Web scraping
- `scikit-learn` - Modelos ML
- `pandas`, `numpy` - Processamento de dados

**InstalaÃ§Ã£o:**

```bash
cd production_api/
pip install -r requirements.txt
```

### Como Rodar a API de ProduÃ§Ã£o

#### 1. ConfiguraÃ§Ã£o do Ambiente

```bash
cd production_api/

# Copie o arquivo de configuraÃ§Ã£o de exemplo
cp config/.env.example config/.env.local

# Edite as configuraÃ§Ãµes conforme necessÃ¡rio
# DATABASE_URL, SECRET_KEY, etc.
```

#### 2. InicializaÃ§Ã£o do Database

```bash
# Inicialize o banco de dados
python init_db.py

# Execute migraÃ§Ãµes (se necessÃ¡rio)
python migrate_db.py
```

#### 3. ExecuÃ§Ã£o da API

```bash
# Modo desenvolvimento
python run_api.py

# Ou com configuraÃ§Ãµes especÃ­ficas
FLASK_ENV=development python run_api.py
```

#### 4. ConfiguraÃ§Ã£o de Jobs Automatizados

```bash
# Configure cron jobs para scraping automÃ¡tico
python setup_cron.py

# Ou execute scraping manual
python run_scraper.py
```

#### 5. Deploy em ProduÃ§Ã£o

```bash
# Use o script de deploy
python deploy.py

# Ou com Docker (se disponÃ­vel)
docker-compose up -d
```

### Funcionalidades da API de ProduÃ§Ã£o

#### ğŸ” ClassificaÃ§Ã£o em Tempo Real
- **Endpoint de ClassificaÃ§Ã£o**: Classifica produtos instantaneamente
- **Batch Processing**: Processa mÃºltiplos produtos em lote
- **Confidence Scoring**: Scores de confianÃ§a para cada prediÃ§Ã£o
- **ExplicaÃ§Ãµes Detalhadas**: Reasoning por trÃ¡s de cada classificaÃ§Ã£o

#### ğŸ•·ï¸ Scraping Automatizado
- **Cron Jobs**: Coleta automÃ¡tica de dados em intervalos regulares
- **Error Handling**: RecuperaÃ§Ã£o automÃ¡tica de falhas
- **Data Validation**: ValidaÃ§Ã£o e limpeza de dados coletados
- **Duplicate Detection**: PrevenÃ§Ã£o de dados duplicados

#### ğŸ“Š Monitoramento e Analytics
- **Health Checks**: Monitoramento contÃ­nuo de componentes
- **Performance Metrics**: MÃ©tricas de latÃªncia, throughput e accuracy
- **System Alerts**: Alertas automÃ¡ticos para problemas
- **Usage Analytics**: EstatÃ­sticas de uso da API

#### ğŸ—ƒï¸ GestÃ£o de Dados
- **Product Management**: CRUD completo para produtos
- **Classification History**: HistÃ³rico completo de classificaÃ§Ãµes
- **Data Export**: ExportaÃ§Ã£o de dados em mÃºltiplos formatos
- **Backup & Recovery**: Sistemas de backup automÃ¡tico

### Endpoints da API

#### ClassificaÃ§Ã£o de Produtos
```bash
# Classificar um produto
curl -X POST http://localhost:5000/api/classify \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Cartucho HP 664 Original",
    "description": "Cartucho original HP",
    "price": 89.90,
    "seller_name": "HP Store Oficial",
    "rating": 4.8,
    "reviews_count": 150
  }'
```

#### Listagem de Produtos
```bash
# Listar produtos com filtros
curl "http://localhost:5000/api/products?prediction=original&limit=10&page=1"

# Filtrar por confianÃ§a
curl "http://localhost:5000/api/products?min_confidence=0.8"
```

#### Monitoramento
```bash
# Status de saÃºde
curl "http://localhost:5000/api/health"

# MÃ©tricas de performance
curl "http://localhost:5000/api/metrics"
```

### Testes da API de ProduÃ§Ã£o

#### Testes UnitÃ¡rios
```bash
cd production_api/tests/

# Execute todos os testes
pytest -v

# Testes especÃ­ficos
pytest test_ml_service.py -v
pytest test_classification_service.py -v
pytest test_api_routes.py -v
```

#### Testes de IntegraÃ§Ã£o
```bash
# Testes end-to-end
pytest test_integration.py -v

# Testes de database
pytest test_database_integration.py -v

# Testes de API
pytest test_api_integration.py -v
```

#### ValidaÃ§Ã£o de Estrutura
```bash
# Validar estrutura dos testes
python tests/validate_integration_tests.py

# Runner de testes integrado
python tests/test_integration_runner.py
```

### Arquivos Principais da API

```
production_api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py              # Factory da aplicaÃ§Ã£o Flask
â”‚   â”œâ”€â”€ models.py                # Modelos de database
â”‚   â”œâ”€â”€ api/routes.py            # Endpoints REST
â”‚   â”œâ”€â”€ services/                # ServiÃ§os de negÃ³cio
â”‚   â””â”€â”€ utils/                   # UtilitÃ¡rios
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.py                # ConfiguraÃ§Ãµes por ambiente
â”‚   â”œâ”€â”€ .env.example             # Template de variÃ¡veis
â”‚   â””â”€â”€ factory.py               # Factory de configuraÃ§Ã£o
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_integration.py      # Testes end-to-end
â”‚   â”œâ”€â”€ test_api_integration.py  # Testes de API
â”‚   â””â”€â”€ conftest.py              # ConfiguraÃ§Ã£o pytest
â”œâ”€â”€ run_api.py                   # Servidor principal
â”œâ”€â”€ init_db.py                   # InicializaÃ§Ã£o database
â”œâ”€â”€ setup_cron.py                # ConfiguraÃ§Ã£o cron jobs
â””â”€â”€ requirements.txt             # DependÃªncias
```

### MÃ©tricas de Performance da API

- **LatÃªncia de ClassificaÃ§Ã£o**: <200ms por produto
- **Throughput**: >100 classificaÃ§Ãµes/minuto
- **Uptime**: >99.5% disponibilidade
- **Accuracy**: >85% precisÃ£o nas classificaÃ§Ãµes
- **Scraping Rate**: >1000 produtos/hora

*Nota: Para documentaÃ§Ã£o detalhada da API, consulte `production_api/README.md` e `production_api/DEPLOYMENT.md`.*

## ğŸ Como Rodar o Projeto Completo (Passo a Passo)

Para rodar o projeto completo do zero, siga os passos abaixo na ordem:

### ConfiguraÃ§Ã£o Inicial do Ambiente

1. **ConfiguraÃ§Ã£o Inicial do Ambiente:** Siga as instruÃ§Ãµes na seÃ§Ã£o "ConfiguraÃ§Ã£o Inicial do Ambiente" para instalar Python, Node.js e pnpm.

### Sprint 1: Coleta e Processamento de Dados

2. **Web Scraping (Opcional - Use dados mockados para agilizar):**
   - Execute `python3 scripts/generate_demo_data.py` para gerar dados mockados do Mercado Livre.
   - Execute `python3 scripts/generate_americanas_mock_data.py` para gerar dados mockados da Americanas.

3. **Processamento de Dados:**
   - Execute `python3 scripts/data_cleaning.py`.
   - Execute `python3 scripts/data_enrichment.py`.
   - Execute `python3 scripts/data_integration.py`.

4. **Rotulagem HeurÃ­stica:**
   - Execute `python3 scripts/heuristic_labeling.py`.
   - Execute `python3 scripts/dataset_generation.py`.

### Sprint 2: AnÃ¡lise ExploratÃ³ria e Observabilidade

5. **AnÃ¡lise ExploratÃ³ria de Dados (EDA):**
   - Navegue atÃ© a pasta `notebooks/` e inicie o Jupyter Notebook (`jupyter notebook`).
   - Abra e execute o `eda_notebook.ipynb` cÃ©lula por cÃ©lula.

6. **Plataforma de Observabilidade:**
   - **Backend:** Siga as instruÃ§Ãµes de instalaÃ§Ã£o e execuÃ§Ã£o do backend (`backend/hp_observability_backend`).
   - **Frontend:** Siga as instruÃ§Ãµes de instalaÃ§Ã£o e execuÃ§Ã£o do frontend (`hp-observability-frontend`).

### Sprint 3: Pipeline de Machine Learning e API de ProduÃ§Ã£o

7. **Pipeline de Machine Learning:**
   - **InstalaÃ§Ã£o das dependÃªncias ML:**
     ```bash
     pip install scikit-learn pandas numpy matplotlib seaborn joblib imbalanced-learn reportlab
     ```
   
   - **ExecuÃ§Ã£o do Pipeline Completo:**
     ```bash
     cd notebooks/
     python ml_pipeline_modular.py
     ```
   
   - **Ou execute mÃ³dulos individuais conforme necessÃ¡rio (ver seÃ§Ã£o Sprint 3 acima)**

8. **API de ProduÃ§Ã£o:**
   - **InstalaÃ§Ã£o das dependÃªncias da API:**
     ```bash
     cd production_api/
     pip install -r requirements.txt
     ```
   
   - **ConfiguraÃ§Ã£o do ambiente:**
     ```bash
     cp config/.env.example config/.env.local
     # Edite config/.env.local com suas configuraÃ§Ãµes
     ```
   
   - **InicializaÃ§Ã£o do database:**
     ```bash
     python init_db.py
     ```
   
   - **ExecuÃ§Ã£o da API:**
     ```bash
     python run_api.py
     ```
     *A API estarÃ¡ disponÃ­vel em `http://localhost:5000`*
   
   - **ConfiguraÃ§Ã£o de scraping automÃ¡tico (opcional):**
     ```bash
     python setup_cron.py
     ```

9. **Testes e ValidaÃ§Ã£o (Opcional mas Recomendado):**
   
   **Testes do Pipeline ML:**
   ```bash
   python notebooks/test_preprocessing.py
   python notebooks/test_hyperparameter_pipeline.py
   python notebooks/test_validation.py
   python notebooks/test_interpretation.py
   python notebooks/test_model_recommendation.py
   ```
   
   **Testes da API de ProduÃ§Ã£o:**
   ```bash
   cd production_api/tests/
   pytest -v
   python test_integration_runner.py
   ```

### Resultado Final

Ao final, vocÃª terÃ¡:

- **Dados coletados e processados** (Sprint 1)
- **AnÃ¡lise exploratÃ³ria completa** com insights e visualizaÃ§Ãµes (Sprint 2)
- **Plataforma de observabilidade** rodando em `http://localhost:5173` (Sprint 2)
- **Pipeline de ML completo** com modelos treinados, otimizados e prontos para produÃ§Ã£o (Sprint 3)
- **API de produÃ§Ã£o** rodando em `http://localhost:5000` com classificaÃ§Ã£o em tempo real (Sprint 3)
- **Sistema de scraping automatizado** com cron jobs e monitoramento (Sprint 3)
- **RelatÃ³rios tÃ©cnicos e executivos** com recomendaÃ§Ãµes de modelos (Sprint 3)
- **Sistema completo de classificaÃ§Ã£o automÃ¡tica** de produtos HP por autenticidade (Sprint 3)

## ğŸ¯ Objetivos AlcanÃ§ados

### Sprint 1 âœ…
- Coleta automatizada de dados de mÃºltiplas fontes
- Limpeza e padronizaÃ§Ã£o de dados
- Rotulagem heurÃ­stica para classificaÃ§Ã£o inicial

### Sprint 2 âœ…  
- AnÃ¡lise exploratÃ³ria abrangente com insights de negÃ³cio
- Plataforma web para monitoramento e observabilidade
- VisualizaÃ§Ãµes interativas e dashboards

### Sprint 3 âœ…
- Pipeline de ML modular e escalÃ¡vel
- ClassificaÃ§Ã£o automÃ¡tica com >85% de accuracy
- Sistema de recomendaÃ§Ã£o inteligente de modelos
- Interpretabilidade e explicabilidade completas
- RelatÃ³rios tÃ©cnicos e executivos automatizados
- **API de produÃ§Ã£o completa** com REST endpoints
- **Sistema de scraping automatizado** com cron jobs
- **Monitoramento e health checks** em tempo real
- **Testes de integraÃ§Ã£o abrangentes** (end-to-end, database, API)
- **Deploy ready** com configuraÃ§Ãµes de produÃ§Ã£o

## ğŸ“Š MÃ©tricas de Sucesso

### Pipeline de Machine Learning
- **Cobertura de Dados**: >1000 produtos coletados e analisados
- **Accuracy do Modelo**: >85% na classificaÃ§Ã£o de autenticidade
- **Tempo de Processamento**: <5 minutos para pipeline completo
- **Interpretabilidade**: ExplicaÃ§Ãµes claras para 100% das prediÃ§Ãµes
- **AutomaÃ§Ã£o**: Pipeline totalmente automatizado do dado bruto ao modelo em produÃ§Ã£o

### API de ProduÃ§Ã£o
- **Performance da API**: <200ms latÃªncia por classificaÃ§Ã£o
- **Throughput**: >100 classificaÃ§Ãµes por minuto
- **Disponibilidade**: >99.5% uptime
- **Scraping Rate**: >1000 produtos coletados por hora
- **Cobertura de Testes**: >90% cobertura de cÃ³digo com testes de integraÃ§Ã£o
- **Monitoramento**: Health checks e mÃ©tricas em tempo real
- **Escalabilidade**: Suporte a processamento em lote e cron jobs automatizados



